{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7682cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tokenizers==0.13.3 -U && pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ece07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from peft import PeftModel\n",
    "from peft.utils import PeftConfig\n",
    "import torch\n",
    "    \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ceed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = \"/mnt/ft-models/llama2-ft-lora-13b-demo\"\n",
    "\n",
    "output_dir = \"llama2-ft-lora-13b-merge-samsum-demo\"\n",
    "\n",
    "base_model_name_or_path= \"meta-llama/Llama-2-13b-hf\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77641186",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name_or_path,\n",
    "    device_map=\"auto\", \n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_auth_token=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(base_model, ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5642b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nModel architecture before merging\", flush=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d7b125",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()\n",
    "\n",
    "print(f\"\\nModel architecture after merging\", flush=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=True,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f27d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = \"\"\"Martin: I won two cinema tickets! Aggie: oh cool, how come? Martin: online. on fb, the movie mag organized it Aggie: so what did you do Martin: just write a short review and that's it Aggie: well done :) so what and when. and where? Martin: the new film with Redford Aggie: i guess i heard sth Martin: it's pretty cool i heard. till the end of the week Aggie: sounds good. we'll find time XD\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ppl(f\"Summarize this dialog:\\n{dialog}\\n---\",\n",
    "    max_length=200,\n",
    "        temperature=0.95,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16b20ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be77be28",
   "metadata": {},
   "source": [
    "# Export to Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490aaefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from ads.model.datascience_model import DataScienceModel\n",
    "from ads.common.auth import default_signer\n",
    "import ads\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.set_auth(\"resource_principal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05edcb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH=output_dir\n",
    "ARTFICAT_FILE_NAME=f\"{os.path.basename(output_dir)}.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile(ARTFICAT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d714e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_archive_file = shutil.make_archive(ARTFICAT_FILE_NAME, format=\"zip\", root_dir=MODEL_PATH)\n",
    "!zip -0 -rj $ARTFICAT_FILE_NAME $MODEL_PATH/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile(ARTFICAT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DISPLAY_NAME = \"LLama2-FT-Lora-13b-Samsum\"\n",
    "bucket = \"your bucket\"\n",
    "namespace = \"your namespace\"\n",
    "OCI_BUCKET = f\"oci://{bucket}@{namespace}/datascience-large-artifact-store/\" # For large models we first upload the model to object storag and then provide the object storage location while creating model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6330446",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DataScienceModel()\n",
    "model = (\n",
    "    model.with_display_name(MODEL_DISPLAY_NAME)\n",
    "    .with_artifact(ARTFICAT_FILE_NAME)\n",
    ")\n",
    "model.create(bucket_uri=OCI_BUCKET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ca6de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch20_p39_gpu_v2]",
   "language": "python",
   "name": "conda-env-pytorch20_p39_gpu_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
